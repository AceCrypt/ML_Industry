{
 "cells": [
  {
   "attachments": {
    "wafer.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "286495c6",
   "metadata": {},
   "source": [
    "# Calibration\n",
    "\n",
    "Modern integrated circuits, or chips, are manufactured using a complex process where the chips are essentially printed onto a silicon wafer (see this **[video](https://www.youtube.com/watch?v=g8Qav3vIv9s)** for an overview of the process). Each wafer contains many chips (e.g. a wafer with 300mm diameter fits several hundred laptop grade microprocessors). The chips on a finished wafer are tested to identify which are good and which are faulty. The yield of a wafer is determined by the fraction of good chips. To maximize the yield, semiconductor manufacturers are interested in identifying and correcting the causes of the faulty chips (e.g. wrong settings in one of processing steps). Some causes can be identified by visual inspection of patterns in a wafer maps, showing which chips are good and which are faulty.\n",
    "\n",
    "![wafer.png](attachment:wafer.png)\n",
    "\n",
    "In this assignment you will work with wafer map data from a semiconductor manufacturing process. Your task will be to develop a calibrated classifier for identifying patterns of faulty chips on a finished wafer. Identifying such patterns can help with optimizing the manufacturing process parameters for the following wafers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab6894",
   "metadata": {},
   "source": [
    "#### Deliverable\n",
    "\n",
    "Throughout this notebook you will find cells starting with `#TODO` and `# // BEGIN_TODO`.\n",
    "\n",
    "- Fill in all these TODO cells. The `#TODO` cells are meant to guide you (you are strongly encouraged to fill these in!), while the `# // BEGIN_TODO` _answer cells_ will be graded.\n",
    "- Answer cells start and end with tags, `# // BEGIN_TODO [Q0]` and `# // END_TODO [Q0]`, for example. Do not edit these tags in any way, or else your answers may not be processed by the grading system.\n",
    "- Be careful when importing additional libraries. The code for of your answers will be evaluated automatically and we cannot guarantee that any additional libraries will be available in that environment. Please check the Momotor output on Canvas after submitting the assignment, you should be able to see if all your code executed without errors. If in doubt, please ask your instructor.\n",
    "- You can add arbitrary many code and text cells between the `# // BEGIN_TODO [Q0]` and `# // END_TODO [Q0]` tags to make your code nicely readable.\n",
    "\n",
    "You are encouraged to play with the data and extend this notebook in order to obtain your answers. You may insert cells at any point in the notebook, but remember:\n",
    "<br/><br/>\n",
    "<div style=\"padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #a94442; background-color: #f2dede; border-color: #ebccd1;\n",
    "\">\n",
    "Only the code in your answer cells (i.e. between `# // BEGIN_TODO` and `# // END_TODO`) will be extracted and evaluated.\n",
    "</div>\n",
    "\n",
    "At the end, deliver the filled in **and executed** `.ipynb` file by submitting it to the corresponding assignment on Canvas. You may submit as many times as you like before the deadline. The last submission counts.\n",
    "\n",
    "> **IMPORTANT:** Before delivering your notebook, make sure that the cells in your notebook can be executed in sequence without errors, by executing \"Restart & Run All\" from the \"Kernel\" menu.\n",
    "\n",
    "Let's get started by filling in your details in the following answer cell. Assign your group number, your names and student ids to variables `group_number`, `name_student1`, `id_student1`, `name_student2`, `id_student2`, e.g.:\n",
    "\n",
    "```\n",
    "# // BEGIN_TODO [AUTHOR]\n",
    "group_number = 7\n",
    "name_student1 = \"John Smith\"\n",
    "id_student1 = \"1234567\"\n",
    "name_student2 = \"Jane Miller\"\n",
    "id_student2 = \"7654321\"\n",
    "# // END_TODO [AUTHOR]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dfd5121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [AUTHOR]\n",
    "group_number = 24\n",
    "name_student1 = \"Mert Gursu Gokcen\"\n",
    "id_student1 = \"1924850\"\n",
    "name_student2 = \"Devansh Mishra\"\n",
    "id_student2 = \"1932551\"\n",
    "#// END_TODO [AUTHOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5849978",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Later, the code in your answer cells will be evaluated in an environment with several typical data science libraries installed, including pandas, numpy, matplotlib, sklearn. You are free to use them.\n",
    "\n",
    "> **IMPORTANT:** Please import any additional libraries inside your answer cells (otherwise your code may crash during evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3514b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7c08a",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The data resides in the `./data/wafer.pkl` pickle file. It is based on the WM-811K dataset containing annotated wafer maps collected from real-world fabrication (see `./data/readme.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "621ad3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wafer.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add901ea",
   "metadata": {},
   "source": [
    "`X` contains wafer maps and `y` contains the labels. The maps are 26x26 pixels, a pixel of value 0 represents the background, a pixel of value 1 indicates a good chip, and a pixel of value 2 indicates a bad chip. An example of a wafer map is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20f2abd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172029",
   "metadata": {
    "tags": []
   },
   "source": [
    "The wafer maps were labeled by human experts according to bad chip patterns, where each label is an integer:\n",
    "\n",
    "- 0: No pattern\n",
    "- 1: Center\n",
    "- 2: Donut\n",
    "- 3: Edge-local\n",
    "- 4: Edge-ring\n",
    "- 5: Local\n",
    "- 6: Near-full\n",
    "- 7: Random\n",
    "- 8: Scratch\n",
    "\n",
    "An example of the wafer map for each pattern is shown below. Note that not all patterns may be present in this particular data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "837764b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_classes, class_indexes = np.unique(y_train,return_index=True)\n",
    "class_names = [\"No pattern\", \"Center\", \"Donut\", \"Edge-local\", \"Edge-ring\", \"Local\", \"Near-full\", \"Random\", \"Scratch\"]\n",
    "fig, axes = plt.subplots(1,len(unique_classes), figsize = (12,5))\n",
    "for num_index, index in enumerate(class_indexes):\n",
    "    axes[num_index].imshow(X_train[index])\n",
    "    axes[num_index].set_title(class_names[unique_classes[num_index]])\n",
    "    axes[num_index].set_xticks([])\n",
    "    axes[num_index].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356882ba",
   "metadata": {},
   "source": [
    "## Train a classifier\n",
    "\n",
    "In this part you will implement a classifier, which will be used later for evaluating your calibration method.\n",
    "\n",
    "First, start by exploring the data. Remember, you can add as many code and markdown cells as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa97794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA for train data:\n",
      "The number of wafer maps in training data is 4160 with a resolution of 26x26 pixels\n",
      "The number of labels for wafer maps is 4160\n",
      "The target values in our training data are the following: [0 1 3 5 6 7] \n",
      "\n",
      "EDA for test data:\n",
      "The number of wafer maps in training data is 2065 with a resolution of 26x26 pixels\n",
      "The number of labels for wafer maps is 2065\n",
      "The target values in our training data are the following: [0 1 3 5 6 7] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data\n",
    "print(\"EDA for train data:\")\n",
    "print(f'The number of wafer maps in training data is {X_train.shape[0]} with a resolution of {X_train.shape[1]}x{X_train.shape[2]} pixels')\n",
    "print(f'The number of labels for wafer maps is {y_train.shape[0]}')\n",
    "print(f'The target values in our training data are the following: {np.unique(y_train)} \\n')\n",
    "\n",
    "\n",
    "print(\"EDA for test data:\")\n",
    "print(f'The number of wafer maps in training data is {X_test.shape[0]} with a resolution of {X_test.shape[1]}x{X_test.shape[2]} pixels')\n",
    "print(f'The number of labels for wafer maps is {y_test.shape[0]}')\n",
    "\n",
    "print(f'The target values in our training data are the following: {np.unique(y_test)} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eeee6c25-668d-45a4-a7c0-be19c98b258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train).any())\n",
    "print(np.isnan(X_train).any(axis=1).any())\n",
    "print(np.isnan(X_train).any(axis=2).any())\n",
    "print(np.isnan(y_train).any())\n",
    "print(np.isnan(X_test).any())\n",
    "print(np.isnan(X_test).any(axis=1).any())\n",
    "print(np.isnan(X_test).any(axis=2).any())\n",
    "print(np.isnan(y_test).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3710e5c0-66c5-4ae4-a3ca-1ff4ef351477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 5 6 7]\n",
      "[0 1 3 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train))\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15945f0c",
   "metadata": {},
   "source": [
    "In the first part of this assignment the aim is to identify whether the wafer map contains any known patterns or not. We therefore treat it as a binary classification problem and replace labels other than 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "420f1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary_train = np.copy(y_train)\n",
    "y_binary_train[y_binary_train != 0] = 1\n",
    "\n",
    "y_binary_test = np.copy(y_test)\n",
    "y_binary_test[y_binary_test != 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8447f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 1\n",
    "\n",
    "Choose a metric for evaluating the classifier's generalization performance and assign your choice to a string variable `classifier_metric_choice`. Motivate the choice (including the hyper-parameters, if any) in a string variable `classifier_metric_motivation` (max 800 characters). Describe how you decide based on this metric if a classifier is sufficiently trained in a string variable `classifier_metric_decision` (max 400 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ddb1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_1] Choose a classifier metric (1 point)\n",
    "\n",
    "classifier_metric_choice = \"Neural Network\"\n",
    "classifier_metric_motivation = \"Baseline peformance check\"\n",
    "classifier_metric_decision = \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a25860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f555f2",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Train a binary classifier on the training set `X_train` and `y_binary_train`. You are free to chose any model and data preprocessing method, as long as:\n",
    "\n",
    "- your classifier outputs the predicted class (0 or 1) and the confidence estimate of the positive class,\n",
    "- your submission executes within 10 minutes on Momotor,\n",
    "- you use the libraries available on Momotor.\n",
    "\n",
    "Evaluate your trained model on the test set `X_test` and `y_binary_test`. What do you observe? How do you know that your model is well trained? Assign your answer to a string variable `observation_classifier` (max 600 characters).\n",
    "\n",
    "Apply the classifier to the `X_test` data and store the predicted classes and confidence estimate in the variables `uncalibrated_y` and `uncalibrated_p`, respectively:\n",
    "\n",
    "- `uncalibrated_y` should be a `np.ndarray` of shape $[N,]$ and `dtype` of `np.int32`, where $N$ is the number of samples and each value is the predicted class,\n",
    "- `uncalibrated_p` should be a `np.ndarray` of shape $[N,]$ and `dtype` of `np.float32`, where each value is the classifier's confidence in the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "074a3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_2] Train a binary classifier (1 point)\n",
    "\n",
    "#flattening 3D array to 2 dimensions \n",
    "X_train_flat = X_train.reshape((4160,-1))\n",
    "X_test_flat = X_test.reshape((2065,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ed130f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "086a8a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(estimator=LogisticRegression(C=0.01))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CalibratedClassifierCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.calibration.CalibratedClassifierCV.html\">?<span>Documentation for CalibratedClassifierCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CalibratedClassifierCV(estimator=LogisticRegression(C=0.01))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.01)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.01)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(estimator=LogisticRegression(C=0.01))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "param_grid={'C':[0.001,0.01,0.1,1,10,100],'class_weight':[None,'balanced']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg,param_grid=param_grid,scoring='neg_log_loss',cv=5)\n",
    "grid_search.fit(X_train_flat,y_binary_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "model = CalibratedClassifierCV(estimator=LogisticRegression(**best_params), method='sigmoid')\n",
    "model.fit(X_train_flat, y_binary_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "\n",
    "#calibrated_log_loss = bin(y_val, calibrated_probs_val)\n",
    "\n",
    "#print(\"Best Hyperparameters:\", best_params)\n",
    "#print(\"Calibrated Log Loss on Validation Set:\", calibrated_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "144180a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_probs_val = model.predict_proba(X_test_flat)[:,1]\n",
    "calibrated_probs_val_train = model.predict_proba(X_train_flat)[:,1]\n",
    "uncalibrated_y = model.predict(X_test_flat)\n",
    "uncalibrated_p = model.predict_proba(X_test_flat)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "baf2d1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = MLPClassifier(solver='sgd',alpha=1e-5,hidden_layer_sizes=(256,128,64,32,16,8,4,2),random_state=1)\\nmodel.fit(X_train_flat,y_binary_train)\\n\\nuncalibrated_y = model.predict(X_test_flat)\\naccuracy = accuracy_score(y_binary_test,uncalibrated_y)\\nprint(f'The accuracy is {accuracy}')\\nuncalibrated_p_ = model.predict_proba(X_test_flat)[:,1]\\n\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = MLPClassifier(solver='sgd',alpha=1e-5,hidden_layer_sizes=(256,128,64,32,16,8,4,2),random_state=1)\n",
    "model.fit(X_train_flat,y_binary_train)\n",
    "\n",
    "uncalibrated_y = model.predict(X_test_flat)\n",
    "accuracy = accuracy_score(y_binary_test,uncalibrated_y)\n",
    "print(f'The accuracy is {accuracy}')\n",
    "uncalibrated_p_ = model.predict_proba(X_test_flat)[:,1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d6bc699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_classifier = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "291017db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c3caa",
   "metadata": {},
   "source": [
    "## Measure and visualize calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c9fcc",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Visualize the calibration of your trained model using a reliability diagram. Describe your observations in the variable `observation_uncalibrated` (max 1000 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1c7d4ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.figure(figsize=(8, 8))\\nprob_true, prob_pred = calibration_curve(y_calib_test, q_calib_test)\\n#prob_true, prob_pred = calibration_curve(y_binary_test, platt_prob)\\nplt.plot(prob_pred, prob_true, marker='o')\\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Ideal')\\nplt.xlabel('Mean Predicted Probability')\\nplt.ylabel('Fraction of Positives')\\nplt.title('Reliability Diagram')\\n\\n# Add legend\\nplt.legend()\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#// BEGIN_TODO [STEP_3] Visualize calibration of uncalibrated model (1 point)\n",
    "'''plt.figure(figsize=(8, 8))\n",
    "prob_true, prob_pred = calibration_curve(y_calib_test, q_calib_test)\n",
    "#prob_true, prob_pred = calibration_curve(y_binary_test, platt_prob)\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Ideal')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Reliability Diagram')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cc9a150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_uncalibrated = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cd674c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6bbb64",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "\n",
    "Choose a calibration metric and assign its name to a string variable `binary_metric_choice`. Motivate the choice (including the hyper-parameters, if any) in a string variable `binary_metric_motivation` (max 800 characters). Describe how you decide based on this metric if a classifier is sufficiently calibrated in a string variable `binary_metric_decision` (max 400 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8ae00973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_4] Choose a calibration metric (1 point)\n",
    "\n",
    "binary_metric_choice = \"Log Loss\"\n",
    "binary_metric_motivation = ''\n",
    "binary_metric_decision = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6bc913ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01295925",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "\n",
    "Implement the chosen calibration metric. It should be a Python class with the following method:\n",
    "\n",
    "- `score(self, p, y)`, where\n",
    "    - `p` is an `np.ndarray` of shape $[N,]$ with the confidence estimates of the *positive class* for $N$ samples.\n",
    "    - `y` is an `np.ndarray` of shape $[N,]$ with the corresponding true labels (0 or 1).\n",
    "    - It returns a `np.float` number with the calibration error.\n",
    "\n",
    "Instantiate the class (setting any relevant hyper-parameters) and assign it to the variable `binary_metric`.\n",
    "\n",
    "Measure the calibration error of your model on `X_test` and `y_binary_test` and assign the result to the variable `binary_uncalibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "59a820dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_5] Implement the calibration metric (1 point)\n",
    "\n",
    "class LogLoss:\n",
    "    def __init__(self, epsilon=1e-15):\n",
    "        self.epsilon = epsilon\n",
    "        self.log_loss = None\n",
    "\n",
    "    def score(self, p, y):\n",
    "        \"\"\"\n",
    "        Calculate multi-class log loss.\n",
    "\n",
    "        Parameters:\n",
    "        - p: 2D array-like or label indicator matrix\n",
    "                  (n_samples, n_classes)\n",
    "                  True labels for each instance.\n",
    "        - y: 2D array-like\n",
    "                  (n_samples, n_classes)\n",
    "                  Predicted probabilities for each class.\n",
    "\n",
    "        Returns:\n",
    "        - log_loss: float\n",
    "                    Multi-class log loss.\n",
    "        \"\"\"\n",
    "        # Ensure inputs are numpy arrays\n",
    "        p = np.array(p)\n",
    "        y = np.array(y)\n",
    "\n",
    "        if len(p.shape) == 1 or p.shape[1] == 1:\n",
    "            p = label_binarize(p, classes=np.unique(p))\n",
    "\n",
    "        # Clip predicted probabilities to avoid log(0) issues\n",
    "        y = np.clip(y, self.epsilon, 1 - self.epsilon)\n",
    "\n",
    "        # Normalize predicted probabilities to sum to 1 for each instance\n",
    "        y /= y.sum(keepdims=True)\n",
    "\n",
    "        # Calculate log loss\n",
    "        self.log_loss = -np.mean(np.sum(p * np.log(y), axis=1))\n",
    "\n",
    "        return self.log_loss\n",
    "\n",
    "#Log loss should be low, it penalizes for predicting wrong with high confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f247db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ExpectedCalibrationError:\n",
    "    def __init__(self, num_bins=10):\n",
    "        self.num_bins = num_bins\n",
    "\n",
    "    def _compute_calibration_error(self, bin_boundaries, bin_confidences, bin_accuracies):\n",
    "        bin_widths = np.diff(bin_boundaries)\n",
    "        calibration_error = np.sum(bin_widths * np.abs(bin_confidences - bin_accuracies))\n",
    "        return calibration_error\n",
    "\n",
    "    def score(self, p, y):\n",
    "        # Ensure inputs are numpy arrays\n",
    "        p = np.array(p)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Binning confidence estimates\n",
    "        bin_boundaries = np.linspace(0, 1, self.num_bins + 1)\n",
    "        bin_indices = np.digitize(p, bin_boundaries, right=True)\n",
    "\n",
    "        # Initialize arrays to store bin-level information\n",
    "        bin_confidences = np.zeros(self.num_bins)\n",
    "        bin_accuracies = np.zeros(self.num_bins)\n",
    "\n",
    "        for i in range(1, self.num_bins + 1):\n",
    "            # Select samples within the current bin\n",
    "            in_bin_mask = (bin_indices == i)\n",
    "            if np.any(in_bin_mask):\n",
    "                # Calculate mean confidence and accuracy for the bin\n",
    "                bin_confidences[i - 1] = np.mean(p[in_bin_mask])\n",
    "                bin_accuracies[i - 1] = np.mean(y[in_bin_mask])\n",
    "\n",
    "        # Calculate calibration error\n",
    "        calibration_error = self._compute_calibration_error(bin_boundaries, bin_confidences, bin_accuracies)\n",
    "\n",
    "        return calibration_error\n",
    "\n",
    "# Instantiate the class with the desired number of bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "50653455",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_proba(X_test_flat)[:,1]\n",
    "probabilities_train = model.predict_proba(X_train_flat)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d7a801eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03632683250838595"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_metric = ExpectedCalibrationError(num_bins=15)\n",
    "ece_uncalib = binary_metric.score(y_binary_test,probabilities)\n",
    "ece_uncalib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c92d2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = LogLoss()\n",
    "binary_uncalibrated=binary_metric.score(y_binary_test,probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b97bac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1b7b9",
   "metadata": {},
   "source": [
    "## Calibrate the classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276d99d",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "\n",
    "Implement at least two calibration methods. Each calibration method should be a Python class with the following methods:\n",
    "\n",
    "- `fit(self, p, y)`, where \n",
    "    - `p` is an `np.ndarray` of shape $[N,]$ with the confidence estimates of the *positive class* for $N$ samples.\n",
    "    - `y` is an `np.ndarray` of shape $[N,]$ with the corresponding true labels (0 or 1).\n",
    "    - It fits the calibration model and returns a reference to `self`.\n",
    "- `predict_proba(self, p)`, where\n",
    "    - `p` is an `np.ndarray` of shape $[N,]$ with confidence estimates of the *positive class* for $N$ samples.\n",
    "    - It returns an `np.ndarray` of shape $[N,]$ with the calibrated confidence estimates for each sample in `p`.\n",
    "\n",
    "> **IMPORTANT:** You are not allowed to use the `sklearn.calibration.CalibratedClassifierCV()` method.\n",
    "\n",
    "Instantiate the calibration methods (setting any relevant hyper-parameters) and assign them to a list variable `binary_calibrators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42dd91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_6] Implement calibration methods (1 point)\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "# Calibration method #1: Platt Scaling (assumes binary classification)\n",
    "class PlattScaling(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.base_estimator = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(64), activation='relu'))\n",
    "\n",
    "    def fit(self,p,y):\n",
    "        p, y = check_X_y(p.reshape(-1,1),y,accept_sparse=True)\n",
    "        \n",
    "\n",
    "        #self.calibrator = SVC(kernel='linear', probability=True)\n",
    "        self.calibrator = self.base_estimator\n",
    "        self.calibrator.fit(p,y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def predict_proba(self,p):\n",
    "\n",
    "        return self.calibrator.predict_proba(p.reshape(-1,1)).astype(np.float32)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9236d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "import numpy as np\n",
    "\n",
    "class IsotonicRegressionCalibration(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.calibrator = None\n",
    "\n",
    "    def fit(self, p, y):\n",
    "        p, y = check_X_y(p.reshape(-1, 1), y, accept_sparse=True)\n",
    "\n",
    "        self.calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "        self.calibrator.fit(p.ravel(), y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, p):\n",
    "        return self.calibrator.transform(p.ravel()).reshape(-1, 1).astype(np.float32)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab504077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "class HistogramBinningCalibration:\n",
    "    def __init__(self, num_bins=10):\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = None\n",
    "        self.calibrated_probs = None\n",
    "\n",
    "    def fit(self, p, y):\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        if len(unique_classes) == 1:\n",
    "            # If there's only one class, set calibrated probabilities to a fixed value (e.g., 0.5)\n",
    "            self.bin_edges = np.linspace(0, 1, self.num_bins + 1)\n",
    "            self.calibrated_probs = np.full(self.num_bins, 0.5)\n",
    "            return self\n",
    "\n",
    "        # Ensure at least one positive sample in each bin\n",
    "        unique_p, counts = np.unique(p[y == 1], return_counts=True)\n",
    "        unique_p = unique_p[counts > 1]\n",
    "\n",
    "        # Compute empirical probabilities for the positive class within each bin\n",
    "        bin_edges = np.linspace(0, 1, self.num_bins + 1)\n",
    "        bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "        emp_probs_pos, _, _ = binned_statistic(p[y == 1], y[y == 1], statistic='mean', bins=bin_edges)\n",
    "\n",
    "        # Ensure that there are at least two positive samples in each bin\n",
    "        emp_probs_pos = np.nan_to_num(emp_probs_pos, nan=0)\n",
    "\n",
    "        # Interpolate to fill empty bins using linear interpolation\n",
    "        non_empty_bins = emp_probs_pos > 0\n",
    "        self.calibrated_probs = np.interp(bin_centers, bin_centers[non_empty_bins], emp_probs_pos[non_empty_bins])\n",
    "\n",
    "        self.bin_edges = bin_edges\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, p):\n",
    "    # Check if there's only one class\n",
    "        if self.calibrated_probs is None:\n",
    "        # If there's only one class, set calibrated probabilities to a fixed value (e.g., 0.5)\n",
    "            return np.full(len(p), 0.5)\n",
    "\n",
    "    # Map bin indices to calibrated probabilities using linear interpolation\n",
    "        calibrated_probs = np.interp(p, self.bin_edges[:-1], self.calibrated_probs)\n",
    "\n",
    "        return np.clip(calibrated_probs, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ad723454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "\n",
    "class SimpleCalibrator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier):\n",
    "        self.base_classifier = base_classifier\n",
    "        self.isotonic_regressor = None\n",
    "\n",
    "    def fit(self, p, y):\n",
    "        p, y = check_X_y(p.reshape(-1, 1), y, accept_sparse=True)\n",
    "\n",
    "        # Train the base classifier\n",
    "        self.base_classifier.fit(p, y)\n",
    "\n",
    "        # Use the base classifier to get predicted probabilities\n",
    "        base_proba = self.base_classifier.predict_proba(p.reshape(-1, 1))[:, 1]\n",
    "\n",
    "        # Fit isotonic regression to calibrate the predicted probabilities\n",
    "        self.isotonic_regressor = IsotonicRegression(out_of_bounds='clip')\n",
    "        self.isotonic_regressor.fit(base_proba, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, p):\n",
    "        base_proba = self.base_classifier.predict_proba(p.reshape(-1, 1))[:, 1]\n",
    "\n",
    "        # Use the trained isotonic regression for calibration\n",
    "        calibrated_proba = self.isotonic_regressor.transform(base_proba)\n",
    "\n",
    "        return calibrated_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a1c10605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Platt = PlattScaling()\n",
    "\n",
    "Platt.fit(probabilities_train,y_binary_train)\n",
    "\n",
    "platt_prob = Platt.predict_proba(probabilities)\n",
    "binary_calibrators = [Platt]\n",
    "platt_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e4ac0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Iso = IsotonicRegressionCalibration()\n",
    "Iso.fit(probabilities_train,y_binary_train)\n",
    "iso_prob = Iso.predict_proba(probabilities)\n",
    "iso_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "56c664c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "base_classifier = RandomForestClassifier()\n",
    "simp = SimpleCalibrator(base_classifier)\n",
    "simp.fit(probabilities_train,y_binary_train)\n",
    "simp_prob = simp.predict_proba(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1aa30c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = HistogramBinningCalibration(num_bins=50)\n",
    "hist.fit(probabilities_train, y_binary_train)\n",
    "hist_probs = hist.predict_proba(probabilities)\n",
    "hist_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2bdb6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c78a9",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "\n",
    "Evaluate the performance of your calibration methods. Describe your observations in the variable `observation_calibrators` (max 2000 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8fac6439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncalibrated LogLoss: 0.03632683250838595\n",
      "Calibrated Platt: 0.03262149492899576\n",
      "Calibrated LogLoss: 0.032092356681823725\n",
      "Calibrated LogLoss: 0.0\n",
      "Calibrated LogLoss: 0.03149847094801223\n"
     ]
    }
   ],
   "source": [
    "#// BEGIN_TODO [STEP_7] Evaluate the calibration method (1 point)\n",
    "\n",
    "binary_uncalibrated = binary_metric.score(y_binary_test,probabilities)\n",
    "print(f'Uncalibrated LogLoss: {binary_uncalibrated}')\n",
    "\n",
    "binary_calibrated_test = binary_metric.score(y_binary_test,platt_prob)\n",
    "print(f'Calibrated Platt: {binary_calibrated_test}')\n",
    "\n",
    "iso_check = binary_metric.score(y_binary_test,iso_prob)\n",
    "print(f'Calibrated LogLoss: {iso_check}')\n",
    "\n",
    "hist_check = binary_metric.score(y_binary_test,hist_probs)\n",
    "print(f'Calibrated LogLoss: {hist_check}')\n",
    "\n",
    "iso_check_newmodel = binary_metric.score(y_binary_test,simp_prob)\n",
    "print(f'Calibrated LogLoss: {iso_check_newmodel}')\n",
    "\n",
    "#Amazing drop in the log loss, which shows the value of calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba6c8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_calibrators = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "16c84a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17787b13",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "\n",
    "Let's evaluate your selected calibration method on the output from different classifier, stored in the `./data/wafer_calibration.pkl` pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5394811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/wafer_calibration.pkl', 'rb') as f:\n",
    "    p_calib_train, p_calib_test, y_calib_train, y_calib_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5e369",
   "metadata": {},
   "source": [
    "`p_calib_train` and `p_calib_test` contain the confidence estimates of a classifier (divided into a training and test set), and `y_calib_train` and `y_calib_test` contain the corresponding true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978bf59",
   "metadata": {},
   "source": [
    "Retrain your calibration methods on `p_calib_train` and `y_calib_train`. Use `p_calib_test` and `y_calib_test` to evaluate your methods. Describe your observations in the variable `observation_other` (max 800 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7fc63ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated LogLoss: 0.020901481310526524\n"
     ]
    }
   ],
   "source": [
    "#// BEGIN_TODO [STEP_8] Evaluate the calibration method on another classifier (1 point)\n",
    "\n",
    "Platt_two = PlattScaling()\n",
    "Platt_two.fit(p_calib_train,y_calib_train)\n",
    "\n",
    "platt_prob_two = Platt.predict_proba(p_calib_test)\n",
    "platt_prob_two\n",
    "\n",
    "\n",
    "p_calib_LogLoss = binary_metric.score(y_calib_test,platt_prob_two)\n",
    "print(f'Calibrated LogLoss: {p_calib_LogLoss}')\n",
    "\n",
    "\n",
    "observation_other = \"The log loss score is slightly lower than the log loss score achieved from our binary classifier. This gap can be reduced by increasing the complexity of our classifier.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6a1e9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated LogLoss: 0.034970110654830924\n"
     ]
    }
   ],
   "source": [
    "iso_two = IsotonicRegressionCalibration()\n",
    "iso_two.fit(p_calib_train,y_calib_train)\n",
    "\n",
    "iso_prob_two = iso_two.predict_proba(p_calib_test)\n",
    "\n",
    "p_calib_LogLoss = binary_metric.score(y_calib_test,iso_prob_two)\n",
    "print(f'Calibrated LogLoss: {p_calib_LogLoss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "675e3f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated LogLoss: 0.0\n"
     ]
    }
   ],
   "source": [
    "hist_two = HistogramBinningCalibration(num_bins=20)\n",
    "hist_two.fit(p_calib_train,y_calib_train)\n",
    "\n",
    "hist_prob_two = hist_two.predict_proba(p_calib_test)\n",
    "\n",
    "p_calib_LogLoss = binary_metric.score(y_calib_test,hist_prob_two)\n",
    "print(f'Calibrated LogLoss: {p_calib_LogLoss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "80e6e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_other = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9220eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315f3aa",
   "metadata": {},
   "source": [
    "#### Step 9\n",
    "\n",
    "Choose your favorite calibration method. Assign the instantiated class implementing your chosen calibration method to the variable `binary_calibrator` and its name to a string variable `binary_calibrator_choice`. Motivate the choice (including hyper-parameters, if any) in a string variable `binary_calibrator_motivation` (max 800 characters).\n",
    "\n",
    "Apply the calibration method to the confidence estimates in `p_calib_test` and assign the calibrated confidence estimates to `q_calib_test` (an `np.ndarray` of shape $[N,]$ and `dtype` of `np.float32`).\n",
    "\n",
    "Measure the calibration error of the calibrated confidence estimates in `q_calib_test` and assign the result to the variable `binary_calibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ea1df57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035146439075469965"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#// BEGIN_TODO [STEP_9] Choose a calibration method (1 point)\n",
    "\n",
    "binary_calibrator_choice = \"Isotonic Regression\"\n",
    "binary_calibrator = PlattScaling()\n",
    "binary_calibrator.fit(p_calib_train,y_calib_train)\n",
    "\n",
    "q_calib_test = binary_calibrator.predict_proba(p_calib_test)\n",
    "binary_calibrated = binary_metric.score(y_calib_test,q_calib_test)\n",
    "binary_calibrated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d46406b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_calibrator_motivation = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "35b07200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f7590",
   "metadata": {},
   "source": [
    "#### Leaderboard (binary)\n",
    "\n",
    "Your grade for this assignment will be based on your position on two leaderboards, one for binary calibration and one for multi-class calibration. Your submission to the leaderboards will be automatically computed based on this notebook after you submit it to the \"Assignment 1: Calibration\" assignment on Canvas.\n",
    "\n",
    "You may submit as many times as you like before the deadline. We will try to update the leaderboard regularily. Your latest submission at the moment the leaderboard is computed will count.\n",
    "\n",
    "The data for the binary leaderboard is stored in the `./data/wafer_leaderboard_binary.pkl` pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "87c7c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/wafer_leaderboard_binary.pkl', 'rb') as f:\n",
    "    p_binary_leaderboard = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4d1c3",
   "metadata": {},
   "source": [
    "The data in `p_binary_leaderboard` comes from a similar distribution to the binary calibration data in `./data/wafer_calibration.pkl`.\n",
    "\n",
    "Apply your `binary_calibrator` to the confidence estimates in `p_binary_leaderboard`. Assign the resulting calibrated confidence esimates to `q_binary_leaderboard`.\n",
    "\n",
    "Assign a nickname to the string variable `leaderboard_nickname` that will be shown on the leaderboard next to your score. If you do not wat to participate on the leaderboard, set it to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d31676b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [LEADERBOARD_BINARY] Join the leaderboard\n",
    "\n",
    "q_binary_leaderboard = binary_calibrator.predict_proba(p_binary_leaderboard)\n",
    "leaderboard_nickname = \"Return of the Durum Bois Part 2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e217c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [LEADERBOARD_BINARY]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73336fb",
   "metadata": {},
   "source": [
    "Run the following cell to create a file with your leaderboard submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ca865b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if leaderboard_nickname is not None:\n",
    "\n",
    "    # perform some sanity checks\n",
    "    assert isinstance(group_number, int), \"group_number is not an integer\"\n",
    "    assert isinstance(leaderboard_nickname, str), \"leaderboard_nickname is not a string\"\n",
    "    assert isinstance(q_binary_leaderboard, np.ndarray), \"q_binary_leaderboard is not an np.ndarray\"\n",
    "    assert q_binary_leaderboard.shape == p_binary_leaderboard.shape, \"q_binary_leaderboard has wrong shape\"\n",
    "\n",
    "    # export the solution to a .json file\n",
    "    with open(\"leaderboard_binary.json\", \"w\") as file:\n",
    "            json.dump({\n",
    "                \"group_number\": group_number,\n",
    "                \"leaderboard_nickname\": leaderboard_nickname,\n",
    "                \"q_binary_leaderboard\": q_binary_leaderboard.tolist()\n",
    "            }, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51b6c2",
   "metadata": {},
   "source": [
    "If all went well, a `leaderboard_binary.json` file should have been created in the same directory as this notebook. **Check that it is created, as this file will be used for your leaderboard submission!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10219b1",
   "metadata": {},
   "source": [
    "## Extend to multi-class classification\n",
    "\n",
    "So far we have assumed a binary classification task. In this part you will implement a calibration metric and method that is applicable to multi-class classification.\n",
    "\n",
    "#### Step 10\n",
    "\n",
    "For evaluating the multi-class calibration metric and method, train a classifier on the multi-class wafer map data `X_train` and `y_train` that was loaded earlier. You are free to chose any model and data preprocessing method, as long as:\n",
    "\n",
    "- your classifier outputs the predicted class and the confidence estimate for each class,\n",
    "- your submission executes within 10 minutes on Momotor,\n",
    "- you use the libraries available on Momotor.\n",
    "\n",
    "Evaluate your trained model on the test set `X_test` and `y_test`. What do you observe? How do you know that your model is well trained? Assign your answer to a string variable `observation_multiclass_classifier` (max 600 characters).\n",
    "\n",
    "Apply the classifier to the `X_test` data and store the predicted classes and confidence estimates in the variables `multi_uncalibrated_y` and `multi_uncalibrated_p`, respectively:\n",
    "\n",
    "- `multi_uncalibrated_y` should be a `np.ndarray` of shape $[N,K]$, with the predicted classes (one-hot encoded), where $N$ is the number of samples and $K$ is the number of classes, i.e. `multi_uncalibrated_y[n][k]` is 1 if the classifier predicted class `k`, otherwise it is 0, \n",
    "- `multi_uncalibrated_p` should be a `np.ndarray` of shape $[N,K]$, with the corresponding confidence estimates, i.e. `multi_uncalibrated_p[n][k]` is the classifier's confidence that the predicted class should be `k`.\n",
    "\n",
    "> **IMPORTANT:** For the wafer dataset $K = 9$ and the class indeces should correspond to the classes listed in section **Load the data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7dc022d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_10] Train a multi-class classifier (1 point)\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c4561cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;poly&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;poly&#x27;, probability=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight='balanced', kernel='poly', probability=True)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi_model = LogisticRegression()\n",
    "#multi_model.fit(X_train_flat,y_train)\n",
    "\n",
    "#multi_uncalibrated_y = multi_model.predict(X_test_flat)\n",
    "#accuracy = accuracy_score(y_test,multi_uncalibrated_y)\n",
    "#print(f'The accuracy is {accuracy}')\n",
    "#multi_uncalibrated_p = multi_model.predict_proba(X_train_flat)\n",
    "\n",
    "multi_model = svm.SVC(kernel=\"poly\", probability=True, class_weight='balanced')\n",
    "multi_model.fit(X_train_flat,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e4fa0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_uncalibrated_y = np.eye(9)[multi_model.predict(X_test_flat)]\n",
    "multi_uncalibrated_p = multi_model.predict_proba(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a590021",
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_uncalibrated_p.shape[1] < 9:\n",
    "    missing_classes = set(range(9)) - set(model.classes_)\n",
    "    for missing_class in missing_classes:\n",
    "        multi_uncalibrated_p = np.insert(multi_uncalibrated_p, missing_class, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7823691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_uncalibrated_p.shape[1] > 9:\n",
    "    multi_uncalibrated_p = multi_uncalibrated_p[:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8cb318d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2065, 9)\n",
      "(2065, 9)\n"
     ]
    }
   ],
   "source": [
    "print(multi_uncalibrated_p.shape)\n",
    "print(multi_uncalibrated_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "068da9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_multiclass_classifier = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3d836b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [0,1,2,3,4,5,6,7,8]\n",
    "y_test_one_hot = np.eye(len(class_labels))[y_test]\n",
    "y_train_one_hot = np.eye(len(class_labels))[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "71968ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c9607",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "\n",
    "Choose a calibration metric and assign your choice to a string variable `multi_calibration_choice`. Motivate the choice (including the hyper-parameters, if any) in a string variable `multi_calibration_motivation` (max 800 characters). Describe how you decide based on this metric if a classifier is sufficiently calibrated in a string variable `multi_calibration_decision` (max 200 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4079883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_11] Choose a multi-class calibration metric (1 point)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n",
    "multi_calibration_choice = \"Log Loss\"\n",
    "multi_calibration_motivation = \"Trying same one used in binary classification\"\n",
    "multi_calibration_decision = \"The lower the scoret the better\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "adfa35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27153f2c",
   "metadata": {},
   "source": [
    "#### Step 12\n",
    "\n",
    "Implement the chosen calibration metric. It should be a Python class with the following method:\n",
    "\n",
    "- `score(self, p, y)`, where\n",
    "    - `p` is a `np.ndarray` of shape $[N,K]$ with the confidence estimates, where $N$ is the number of samples and $K$ is the number of classes,\n",
    "    - `y` is a `np.ndarray` of shape $[N,K]$ with the corresponding true class labels (one-hot encoded)\n",
    "    - It returns a `np.float` number with the calibration error.\n",
    "\n",
    "Instantiate the class (setting any relevant hyper-parameters) and assign it to the variable `multi_metric`.\n",
    "\n",
    "Measure the calibration error of your model on `X_test` and `y_test` and assign the result to the variable `multi_uncalibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9bb587e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_12] Implement the multi-class calibration metric (1 point)\n",
    "\n",
    "\n",
    "class LogLossMulti:\n",
    "    def __init__(self, epsilon=1e-15):\n",
    "        self.epsilon = epsilon\n",
    "        self.log_loss = None\n",
    "\n",
    "    def score(self,y_prob,y_true):\n",
    "        \"\"\"\n",
    "        Calculate multi-class log loss.\n",
    "\n",
    "        Parameters:\n",
    "        - y_true: 2D array-like or label indicator matrix\n",
    "                  (n_samples, n_classes)\n",
    "                  True labels for each instance.\n",
    "        - y_prob: 2D array-like\n",
    "                  (n_samples, n_classes)\n",
    "                  Predicted probabilities for each class.\n",
    "\n",
    "        Returns:\n",
    "        - log_loss: float\n",
    "                    Multi-class log loss.\n",
    "        \"\"\"\n",
    "        # Ensure inputs are numpy arrays\n",
    "        y_true = np.array(y_true)\n",
    "        y_prob = np.array(y_prob)\n",
    "\n",
    "        \n",
    "\n",
    "        # Clip predicted probabilities to avoid log(0) issues\n",
    "        y_prob = np.clip(y_prob, self.epsilon, 1 - self.epsilon)\n",
    "\n",
    "        # Normalize predicted probabilities to sum to 1 for each instance\n",
    "        y_prob /= y_prob.sum(keepdims=True)\n",
    "\n",
    "        # Calculate log loss\n",
    "        self.log_loss = -np.mean(np.sum(y_true * np.log(y_prob), axis=1))\n",
    "\n",
    "        return self.log_loss\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "99d9699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class CalibrationMetricMulti:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def score(self, p, y):\n",
    "        \"\"\"\n",
    "        Calculate calibration error based on log loss.\n",
    "\n",
    "        Parameters:\n",
    "        - p: np.ndarray, shape (N, K)\n",
    "            Confidence estimates where N is the number of samples and K is the number of classes.\n",
    "        - y: np.ndarray, shape (N, K)\n",
    "            True class labels (one-hot encoded).\n",
    "\n",
    "        Returns:\n",
    "        - float\n",
    "            Calibration error based on log loss.\n",
    "        \"\"\"\n",
    "        return log_loss(y, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "722b2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.425427877257973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "multi_metric = CalibrationMetricMulti()\n",
    "\n",
    "multi_uncalibrated = multi_metric.score(multi_uncalibrated_p,y_test_one_hot)\n",
    "print(multi_uncalibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b90c41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41bb2fb",
   "metadata": {},
   "source": [
    "#### Step 13\n",
    "\n",
    "Implement at least one calibration method. Each calibration method should be a Python class with the following methods:\n",
    "\n",
    "- `fit(self, p, y)`: where \n",
    "    - `p` is a `np.ndarray` of shape $[N,K]$ with the confidence estimates, where $N$ is the number of samples and $K$ is the number of classes,\n",
    "    - `y` is a `np.ndarray` of shape $[N,K]$ with the corresponding true class labels (one-hot encoded)\n",
    "    - It fits the calibration model and returns a reference to `self`.\n",
    "\n",
    "- `predict_proba(self, p)`: where\n",
    "    - `p` is a `np.ndarray` of shape $[N,K]$ with the confidence estimates, where $N$ is the number of samples and $K$ is the number of classes,\n",
    "    - It returns an `np.ndarray` of shape $[N,K]$ with the calibrated confidence estimates for each sample in `p`.\n",
    "\n",
    "> **IMPORTANT:** You are not allowed to use the `sklearn.calibration.CalibratedClassifierCV()` method.\n",
    "\n",
    "Instantiate the calibration methods (setting any relevant hyper-parameters) and assign them to a list variable `multi_calibrators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "08e5cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_13] Implement multi-class calibration methods (1 point)\n",
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from scipy.special import expit\n",
    "num_classess=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "41a2ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsotonicRegressionCalibrationMulti:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.calibrators = [IsotonicRegression(out_of_bounds='clip') for _ in range(num_classes)]\n",
    "\n",
    "    def fit(self, p, y):\n",
    "        # Ensure inputs are numpy arrays\n",
    "        p = np.array(p)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Check if p and y have the same number of samples\n",
    "        if p.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"Number of samples in p and y must be the same.\")\n",
    "\n",
    "        # Transpose the arrays to have shape (num_samples, num_classes)\n",
    "        p = p.T\n",
    "        y = y.T\n",
    "\n",
    "        for class_idx in range(self.num_classes):\n",
    "            calibrator = self.calibrators[class_idx]\n",
    "\n",
    "            # Extract the class probabilities for the current class\n",
    "            class_probs = p[class_idx]\n",
    "\n",
    "            # Extract the true labels for the current class\n",
    "            class_labels = y[class_idx]\n",
    "\n",
    "            # Fit the calibrator for the current class\n",
    "            calibrator.fit(class_probs, class_labels)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, p):\n",
    "        calibrated_probs = np.zeros_like(p)\n",
    "\n",
    "        # Apply isotonic calibration separately for each class\n",
    "        for class_idx in range(self.num_classes):\n",
    "            calibrator = self.calibrators[class_idx]\n",
    "\n",
    "            # Transform the class probabilities using the calibrator\n",
    "            calibrated_probs[:, class_idx] = calibrator.transform(p[:, class_idx])\n",
    "\n",
    "        return calibrated_probs[:, :self.num_classes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6a66d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class PlattScalingMulti1(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=None):\n",
    "        if base_estimator is None:\n",
    "            self.base_estimator = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(8), activation='relu'))\n",
    "        else:\n",
    "            self.base_estimator = base_estimator\n",
    "\n",
    "    def fit(self, p, y):\n",
    "        p, y = check_X_y(p, y, accept_sparse=True)\n",
    "\n",
    "        self.calibrator = clone(self.base_estimator)\n",
    "        self.calibrator.fit(p, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, p):\n",
    "        calibrated_probs = np.zeros((p.shape[0], np.unique(self.calibrator.classes_).shape[0]), dtype=np.float32)\n",
    "        calibrated_probs[:, self.calibrator.classes_] = self.calibrator.predict_proba(p).astype(np.float32)\n",
    "\n",
    "        return calibrated_probs\n",
    "\n",
    "# Example usage:\n",
    "# num_classes = 9  # Update with the actual number of classes\n",
    "# multi_calibrator = PlattScaling()\n",
    "# multi_calibrator.fit(p, y)\n",
    "# calibrated_probs = multi_calibrator.predict_proba(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8d271d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HistogramBinningCalibrationMulti:\n",
    "    def __init__(self, num_bins=10):\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = None\n",
    "        self.calibration_factors = None\n",
    "\n",
    "    def fit(self, p, y):\n",
    "        # Ensure y is one-hot encoded\n",
    "        assert len(y.shape) == 2 and y.shape[1] > 1, \"Input y should be one-hot encoded.\"\n",
    "\n",
    "        # Flatten predicted probabilities and get corresponding true labels\n",
    "        p_flat = p.flatten()\n",
    "        y_flat = y.argmax(axis=1)\n",
    "\n",
    "        # Calculate bin edges based on predicted probabilities\n",
    "        self.bin_edges = np.histogram_bin_edges(p_flat, bins=self.num_bins)\n",
    "\n",
    "        # Assign each sample to a bin\n",
    "        bin_indices = np.digitize(p_flat, self.bin_edges, right=True)\n",
    "\n",
    "        # Calculate calibration factors for each bin\n",
    "        self.calibration_factors = np.zeros(self.num_bins)\n",
    "        for i in range(1, self.num_bins + 1):\n",
    "            bin_mask = (bin_indices == i)\n",
    "            correct_predictions = np.sum((y_flat[bin_mask] == i - 1))\n",
    "            total_predictions = np.sum(bin_mask)\n",
    "            self.calibration_factors[i - 1] = correct_predictions / max(total_predictions, 1)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, p):\n",
    "        # Assign each sample to a bin\n",
    "        bin_indices = np.digitize(p.flatten(), self.bin_edges, right=True)\n",
    "\n",
    "        # Apply calibration factors based on the bin of each predicted probability\n",
    "        calibrated_p = np.zeros_like(p.flatten())\n",
    "        for i in range(1, self.num_bins + 1):\n",
    "            bin_mask = (bin_indices == i)\n",
    "            calibrated_p[bin_mask] = p.flatten()[bin_mask] * self.calibration_factors[i - 1]\n",
    "\n",
    "        # Normalize calibrated probabilities for each sample\n",
    "        calibrated_p /= calibrated_p.sum()\n",
    "\n",
    "        return calibrated_p.reshape(p.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "81e0cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler()\n",
    "class PlattScalingMulti2:\n",
    "    def __init__(self):\n",
    "        self.calibrator = LogisticRegression()\n",
    "\n",
    "    def fit(self, p, y):\n",
    "        self.calibrator.fit(np.log(p + 1e-9), np.argmax(y, axis=1))\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, p):\n",
    "        return self.calibrator.predict_proba(np.log(p + 1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "800e9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_predictions(proba, wafer_classes):\n",
    "    zero_col = [[0] for _ in range(len(proba))]\n",
    "    target = proba\n",
    "    for i in range(num_classess):\n",
    "        if i not in wafer_classes:\n",
    "            target = np.hstack((target[:,:i], zero_col, target[:,i:]))\n",
    "    return target\n",
    "def format_predictions_one_hot(y_pred):\n",
    "    b = np.zeros((y_pred.size, num_classess))\n",
    "    b[np.arange(y_pred.size), y_pred] = 1\n",
    "    return b\n",
    "def format_predictions_all(proba, y_pred):\n",
    "    wafer_classes = np.unique(y_pred)\n",
    "    return format_predictions(proba, wafer_classes), format_predictions_one_hot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "01d4caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_y_preds = multi_model.predict(X_test_flat)\n",
    "multi_y_proba = multi_model.predict_proba(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "51186162",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_p, final_y = format_predictions_all(multi_y_proba,multi_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "171c7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_calibrators = [IsotonicRegressionCalibrationMulti(num_classes=9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "81430a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a2430",
   "metadata": {},
   "source": [
    "#### Step 14\n",
    "\n",
    "Evaluate the performance of your calibration methods. Assign the instantiated class implementing your chosen calibration method to the variable `multiclass_calibrator` and its name to a string variable `multiclass_calibrator_choice`. Motivate the choice (including hyper-parameters, if any) in a string variable `multiclass_calibrator_motivation` (max 800 characters).\n",
    "\n",
    "Apply the chosen calibration method to your model on the test data `X_test` and assign the calibrated confidence estimates to `q_multi_test` (an `np.ndarray` of shape $[N,K]$ and `dtype` of `np.float32`).\n",
    "\n",
    "Measure the calibration error of the calibrated model and assign the result to the variable `multi_calibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "12713a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#// BEGIN_TODO [STEP_14] Choose a multi-class calibration method (1 point)\n",
    "\n",
    "multiclass_calibrator = PlattScalingMulti2()\n",
    "multiclass_calibrator_choice = ''\n",
    "multiclass_calibrator_motivation = ''\n",
    "\n",
    "\n",
    "\n",
    "multiclass_calibrator.fit(final_p,final_y)\n",
    "q_multi_test = multiclass_calibrator.predict_proba(final_p)\n",
    "\n",
    "q_multi_test = format_predictions(q_multi_test, np.unique(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9d788bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.601019098714621"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_calibrated = multi_metric.score(q_multi_test,y_test_one_hot)\n",
    "multi_calibrated\n",
    "#score has increased, need to change the calibration metric and adapt for multiclass most likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f9ab922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d90757",
   "metadata": {},
   "source": [
    "#### Multi-class leaderboard\n",
    "\n",
    "The `./data/wafer_leaderboard_multiclass.pkl` pickle file contains the data that you can use for training your `multiclass_calibrator`, and the data for computing your submission to the leaderboard data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "968aaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/wafer_leaderboard_multiclass.pkl', 'rb') as f:\n",
    "    p_multiclass_leaderboard_train, y_multiclass_leaderboard_train, p_multiclass_leaderboard = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e60297",
   "metadata": {},
   "source": [
    "Train your `multiclass_calibrator` on the confidence estimates in `p_multiclass_leaderboard_train` and the corresponding true class labels in `y_multiclass_leaderboard_train`.\n",
    "\n",
    "Apply your `multiclass_calibrator` to the confidence estimates in `p_multiclass_leaderboard`. Assign the resulting calibrated confidence esimates to `q_multiclass_leaderboard`.\n",
    "\n",
    "Assign a nickname to the string variable `leaderboard_nickname` that will be shown on the leaderboard next to your score. If you do not wat to participate on the leaderboard, set it to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "163fa92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#// BEGIN_TODO [LEADERBOARD_MULTICLASS] Join the leaderboard\n",
    "y_multiclass_leaderboard_train_onehot = format_predictions_one_hot(y_multiclass_leaderboard_train.astype(int))\n",
    "multiclass_calibrator.fit(p_multiclass_leaderboard_train,y_multiclass_leaderboard_train_onehot)\n",
    "q_multiclass_leaderboard = multiclass_calibrator.predict_proba(p_multiclass_leaderboard)\n",
    "q_multiclass_leaderboard = format_predictions(q_multiclass_leaderboard,np.unique(y_multiclass_leaderboard_train))\n",
    "leaderboard_nickname = 'Big Durum Bois Multiverse'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2e8fbfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [LEADERBOARD_MULTICLASS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010404e",
   "metadata": {},
   "source": [
    "Run the following cell to create a file with your leaderboard submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4fc58b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if leaderboard_nickname is not None:\n",
    "    \n",
    "    # perform some sanity checks\n",
    "    assert isinstance(group_number, int), \"group_number is not an integer\"\n",
    "    assert isinstance(leaderboard_nickname, str), \"leaderboard_nickname is not a string\"\n",
    "    assert isinstance(q_multiclass_leaderboard, np.ndarray), \"q_multiclass_leaderboard is not an np.ndarray\"\n",
    "    assert q_multiclass_leaderboard.shape == p_multiclass_leaderboard.shape, \"q_multiclass_leaderboard has wrong shape\"\n",
    "\n",
    "    # export the solution to a .json file\n",
    "    with open(\"leaderboard_multiclass.json\", \"w\") as file:\n",
    "        json.dump({\n",
    "            \"group_number\": group_number,\n",
    "            \"leaderboard_nickname\": leaderboard_nickname,\n",
    "            \"q_multiclass_leaderboard\": q_multiclass_leaderboard.tolist()\n",
    "        }, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81f503",
   "metadata": {},
   "source": [
    "If all went well, a `leaderboard_multiclass.json` file should have been created in the same directory as this notebook.  **Check that it is created, as this file will be used for your leaderboard submission!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c227cdb",
   "metadata": {},
   "source": [
    "#### Step 15\n",
    "\n",
    "A well calibrated classifier can also be used to identify whether a test sample is out-of-distribution, i.e. if it is very different from the data that the classifier was trained on. The `ood.pkl` file contains several out-of-distribution samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2d3e8e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./data/ood.pkl', 'rb') as f:\n",
    "    X_ood = pickle.load(f)\n",
    "    \n",
    "plt.imshow(X_ood[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55702d57",
   "metadata": {},
   "source": [
    "Evaluate your classifier and calibration method on the data in `X_ood`. Describe your observations in a string variable `observation_ood` (max 1000 characters). Describe one drawback of this approach for identifying out-of-distribution samples in a string variable `drawback_ood` (max 500 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "14fc53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_15] (1 point)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n",
    "observation_ood = ''\n",
    "drawback_ood = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9e64c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2d4a2",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "\n",
    "Please fill in this questionaire to help us improve this course for the next year. Your feedback will be anonymized and will not affect your grade in any way!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4323869",
   "metadata": {},
   "source": [
    "### How many hours did you spend on this assignment?\n",
    "\n",
    "Assign a number to variable `feedback_time`. Please fill in the average among all group members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7e209271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_1] (0 points)\n",
    "feedback_time = 25 \n",
    "#// END_FEEDBACK [Feedback_1]\n",
    "\n",
    "import numbers\n",
    "assert isinstance(feedback_time, numbers.Number), \"Please assign a number to variable feedback_time\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df9e1a",
   "metadata": {},
   "source": [
    "### How difficult did you find this assignment?\n",
    "\n",
    "Assign an integer to variable `feedback_difficulty`, on a scale 0 - 10, with 0 being very easy, 5 being just right, and 10 being very difficult. Please fill in the average among all group members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c44da128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_2] (0 points)\n",
    "feedback_difficulty = 7\n",
    "#// END_FEEDBACK [Feedback_2]\n",
    "\n",
    "assert isinstance(feedback_difficulty, numbers.Number), \"Please assign a number to variable feedback_difficulty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968bde4",
   "metadata": {},
   "source": [
    "### Which Machine Learning-related courses did you complete (TUE/workshop/online/etc.)?\n",
    "\n",
    "Assign a string to variable `feedback_courses`, listing any ML courses any of your group members followed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e9b570b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_3] (0 points)\n",
    "feedback_courses = 'MLOps from DTU, MLEngg'\n",
    "#// END_FEEDBACK [Feedback_3]\n",
    "\n",
    "assert isinstance(feedback_courses, str), \"Please assign a string to variable feedback_courses\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3790e84",
   "metadata": {},
   "source": [
    "### (Optional) What did you like?\n",
    "\n",
    "Assign a string to variable `feedback_like`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "78831b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_4] (0 points)\n",
    "feedback_like = 'I do kaggle competitions often, and this fun in a similar way'\n",
    "#// END_FEEDBACK [Feedback_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b74a0b",
   "metadata": {},
   "source": [
    "### (Optional) What can be improved?\n",
    "\n",
    "Assign a string to variable `feedback_improve`. Please be specific, so that we can act on your feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "09c79c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_5] (0 points)\n",
    "feedback_improve = 'Cant momotor save the scores from the ipynb and create the leaderboards just based on this? This way all notebooks wont have to run again to refresh the leaderboard.'\n",
    "#// END_FEEDBACK [Feedback_5]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
